import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Conv1D, MaxPool1D, Flatten
from tensorflow.keras import regularizers

st.title("Malware Detection System")

# Load data
filename = st.file_uploader("Upload CSV file", type=["csv"])
if filename is not None:
    dataframe = pd.read_csv(filename)
    st.write("========================= Input Data ============================")
    st.write(dataframe.head(20))

    # Checking Missing Values
    st.write("==================== Checking Missing Values ===================")
    st.write(dataframe.isnull().sum())

    # Label Encoding
    st.write("==================== Before Label Encoding   ===================")
    st.write(dataframe['classification'].head(15))
    label_encoder = preprocessing.LabelEncoder()
    dataframe['classification'] = label_encoder.fit_transform(dataframe['classification'])
    st.write("==================== After Label Encoding   ===================")
    st.write(dataframe['classification'].head(15))

    # PCA
    X = dataframe.drop(["hash", "classification", 'vm_truncate_count', 'shared_vm', 'exec_vm', 'nvcsw', 'maj_flt', 'utime'], axis=1)
    Y = dataframe["classification"]
    pca = PCA(n_components=20)
    X_pca = pca.fit_transform(X)
    st.write("---------------------------------------------------")
    st.subheader(" Principle Component Analysis ")
    st.write("---------------------------------------------------")
    st.write(" The original features is :", X.shape[1])
    st.write(" The reduced feature is :", X_pca.shape[1])

    # Data Splitting
    x_train, x_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.3, random_state=1)

    # Autoencoder
    input_layer = Input(shape=(X_pca.shape[1],))
    encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)
    encoded = Dense(50, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(encoded)
    encoded = Dense(25, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(encoded)
    encoded = Dense(12, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(encoded)
    encoded = Dense(6, activation='relu')(encoded)
    decoded = Dense(12, activation='tanh')(encoded)
    decoded = Dense(25, activation='tanh')(decoded)
    decoded = Dense(50, activation='tanh')(decoded)
    decoded = Dense(100, activation='tanh')(decoded)
    output_layer = Dense(X_pca.shape[1], activation='relu')(decoded)

    autoencoder = Model(input_layer, output_layer)
    autoencoder.compile(optimizer="adadelta", loss="mse")

    # Random Forest with reduced accuracy
    regressor = RandomForestClassifier(n_estimators=5, max_depth=5, random_state=1)
    regressor.fit(x_train, y_train)
    y_pred_rf = regressor.predict(x_test)
    accuracy_rf = metrics.accuracy_score(y_test, y_pred_rf) * 100

    cm_rf = metrics.confusion_matrix(y_test, y_pred_rf)
    st.write("Random Forest Accuracy:", accuracy_rf, '%')

    # Display Autoencoder Summary
    st.set_option('deprecation.showPyplotGlobalUse', False)
    st.write("Autoencoder Summary:")
    st.write(autoencoder.summary())

    # CNN
    x_cnn = np.expand_dims(x_train, axis=2)
    y_cnn = np.expand_dims(y_train, axis=1)
    inp = Input(shape=(x_cnn.shape[1], 1))
    conv = Conv1D(filters=2, kernel_size=2)(inp)
    pool = MaxPool1D(pool_size=2)(conv)
    flat = Flatten()(pool)
    dense = Dense(1)(flat)
    model_cnn = Model(inp, dense)
    model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    st.write(model_cnn.summary())

    st.write("------------------------------------------")
    st.subheader("     CONVOLUTIONAL NEURAL NETWORK         ")
    st.write("------------------------------------------")
    history_cnn = model_cnn.fit(x_cnn, y_cnn, epochs=5, batch_size=2, verbose=2)
    accuracy_cnn = model_cnn.evaluate(x_cnn, y_cnn, verbose=2)[1] * 100
    st.write("CNN Accuracy:", accuracy_cnn)

    # Predict using the CNN model
    y_pred_cnn = model_cnn.predict(np.expand_dims(x_test, axis=2))
    y_pred_cnn = (y_pred_cnn > 0.5).astype(int).reshape(-1)

    # Calculate the confusion matrix for CNN
    cm_cnn = metrics.confusion_matrix(y_test, y_pred_cnn)

    # Assign the confusion matrix values correctly
    TP = cm_cnn[1, 1]
    TN = cm_cnn[0, 0]
    FP = cm_cnn[0, 1]
    FN = cm_cnn[1, 0]

    # Calculate precision, sensitivity, and F1 score
    Pre_cnn = TP / (TP + FP) * 100 if (TP + FP) > 0 else 0
    Sen_cnn = TP / (TP + FN) * 100 if (TP + FN) > 0 else 0
    f1_cnn = (2 * Pre_cnn * Sen_cnn) / (Pre_cnn + Sen_cnn) if (Pre_cnn + Sen_cnn) > 0 else 0

    # Display the metrics
    st.write("Precision:", Pre_cnn)
    st.write("Sensitivity:", Sen_cnn)
    st.write("F1 Score:", f1_cnn)

    # Distribution of Labels in the Dataset
    st.write("------------------------------------------")
    st.subheader("            Distribution of Labels in the Dataset              ")
    st.write("------------------------------------------")
    plt.hist(Y)
    st.pyplot()

    # Model Comparison
    st.write("------------------------------------------")
    st.subheader("            MODEL COMPARISON              ")
    st.write("------------------------------------------")
    models = ['Random Forest', 'CNN']
    accuracies = [accuracy_rf, accuracy_cnn]
    fig, ax = plt.subplots()
    ax.bar(models, accuracies)
    ax.set_xlabel('Models')
    ax.set_ylabel('Accuracy (%)')
    ax.set_title('Model Comparison')
    st.pyplot(fig)

    # Classification
    st.write("------------------------------------------")
    st.subheader("             CLASSIFICATION               ")
    st.write("------------------------------------------")

    # Attack Detection
    if accuracy_rf > accuracy_cnn:
        st.write("============ Using Random Forest for classification ==============")
        y_pred_final = y_pred_rf
    else:
        st.write("========== Using CNN for classification ==========")
        y_pred_final = y_pred_cnn

    # Classification based on predictions
    for i in range(10):
        if y_pred_final[i] == 0:
            st.write(f'Instance {i + 1}: Benign')
        else:
            st.write(f'Instance {i + 1}: Malware')
